{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Displaying file names in the specified directory\n",
        "for root, dirs, files in os.walk('/kaggle/input'):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))\n",
        "\n",
        "# Loading the datasets\n",
        "train_df = pd.read_csv('/content/twitter_training.csv', header=None, names=['ID', 'Entity', 'Sentiment', 'Content'])\n",
        "test_df = pd.read_csv('/content/twitter_validation.csv', header=None, names=['ID', 'Entity', 'Sentiment', 'Content'])\n",
        "\n",
        "# Dropping unnecessary columns\n",
        "train_df = train_df.drop(columns=['ID', 'Entity'])\n",
        "test_df = test_df.drop(columns=['ID', 'Entity'])\n",
        "\n",
        "# Checking for null values\n",
        "print(train_df.isnull().sum())\n",
        "\n",
        "# Checking the shape of the training data\n",
        "print(train_df.shape)\n",
        "\n",
        "# Removing null values\n",
        "train_df = train_df.dropna()\n",
        "test_df = test_df.dropna()\n",
        "\n",
        "# Removing duplicates\n",
        "train_df = train_df.drop_duplicates()\n",
        "test_df = test_df.drop_duplicates()\n",
        "\n",
        "# Verifying that no null values are left in the test data\n",
        "print(test_df.isnull().sum())\n",
        "\n",
        "# Combining the training and test datasets\n",
        "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
        "\n",
        "# Checking the shape and duplicates in the combined dataset\n",
        "print(combined_df.shape)\n",
        "print(combined_df.duplicated().sum())\n",
        "\n",
        "# Removing duplicates in the combined dataset\n",
        "combined_df = combined_df.drop_duplicates()\n",
        "\n",
        "# Final verification of duplicates\n",
        "print(\"Number of duplicates in the combined dataset:\", combined_df.duplicated().sum())\n",
        "print(combined_df.shape)\n",
        "\n",
        "# Adding a column for the length of the tweet content\n",
        "combined_df['Content_Length'] = combined_df['Content'].apply(len)\n",
        "\n",
        "# Displaying the combined dataset\n",
        "print(combined_df)\n",
        "\n",
        "# Counting the occurrences of each sentiment\n",
        "print(combined_df['Sentiment'].value_counts())\n",
        "\n",
        "# Replacing 'Neutral' and 'Irrelevant' sentiments with 'Neutral'\n",
        "combined_df['Sentiment'] = combined_df['Sentiment'].apply(lambda x: 'Neutral' if x in ['Neutral', 'Irrelevant'] else x)\n",
        "\n",
        "# Displaying the count of each sentiment after replacement\n",
        "print(combined_df['Sentiment'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q2JRGlp9QU0",
        "outputId": "2db93132-dbef-4394-fcbd-0c515a8aefc7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment      0\n",
            "Content      686\n",
            "dtype: int64\n",
            "(74682, 2)\n",
            "Sentiment    0\n",
            "Content      0\n",
            "dtype: int64\n",
            "(70768, 2)\n",
            "516\n",
            "Number of duplicates in the combined dataset: 0\n",
            "(70252, 2)\n",
            "        Sentiment                                            Content  \\\n",
            "0        Positive  im getting on borderlands and i will murder yo...   \n",
            "1        Positive  I am coming to the borders and I will kill you...   \n",
            "2        Positive  im getting on borderlands and i will kill you ...   \n",
            "3        Positive  im coming on borderlands and i will murder you...   \n",
            "4        Positive  im getting on borderlands 2 and i will murder ...   \n",
            "...           ...                                                ...   \n",
            "70756     Neutral  ♥️ Suikoden 2\\n1️⃣ Alex Kidd in Miracle World\\...   \n",
            "70757    Positive  Thank you to Matching funds Home Depot RW paym...   \n",
            "70759     Neutral  Late night stream with the boys! Come watch so...   \n",
            "70763  Irrelevant  ⭐️ Toronto is the arts and culture capital of ...   \n",
            "70764  Irrelevant  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...   \n",
            "\n",
            "       Content_Length  \n",
            "0                  53  \n",
            "1                  51  \n",
            "2                  50  \n",
            "3                  51  \n",
            "4                  57  \n",
            "...               ...  \n",
            "70756             109  \n",
            "70757             169  \n",
            "70759             197  \n",
            "70763             281  \n",
            "70764             248  \n",
            "\n",
            "[70252 rows x 3 columns]\n",
            "Sentiment\n",
            "Negative      21329\n",
            "Positive      19271\n",
            "Neutral       17281\n",
            "Irrelevant    12371\n",
            "Name: count, dtype: int64\n",
            "Sentiment\n",
            "Neutral     29652\n",
            "Negative    21329\n",
            "Positive    19271\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}